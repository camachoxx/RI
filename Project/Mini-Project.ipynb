{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project: A Simple Search Engine from Scratch\n",
    "In this mini-project you will study the fundaments of IR.\n",
    "\n",
    "The mini-project is divided as follow:\n",
    "\n",
    "- **Week 1**: Study the provided notebook. Using the VSM retrieval model, run experiments *(section 4)* with the provided collection. Compute the metrics MAP, P10 and precision-recall curves.\n",
    "\n",
    "- **Week 2**: Implement the LMD and LMJM retrieval models and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "- **Week 3**: Implement the RM3 retrieval model and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "- **Week 4**: Implement the BM25 retrieval model and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "**Submission date: 15 October**\n",
    "\n",
    "## 1. Vector Space Model\n",
    "\n",
    "In the vector space model, documents are represented as a vector $d_j=(w_{d_j,1},w_{d_j,2}, ..., w_{d_j,n})$ of $n$ word frequencies -- most of the words are equal to 0. Queries are also represented as a vector of words $q_j=(w_{q_j,1},w_{q_j,2}, ..., w_{q_j,n})$. In the vector space model, each document word is weighted by their *tf-idf*\n",
    "\n",
    "$${tf-idf} = tf*\\frac{|D|}{log (df(w_a))}$$\n",
    "\n",
    "The vector space model is based on the cosine similarity, which measures the angle between the two vectors in the 1-unit sphere:\n",
    "\n",
    "$$cos(q,d) = \\frac{\\sum_t q_t\\cdot d_t}{\\sqrt{\\sum_t q^2_t}\\cdot \\sqrt{\\sum_t d^2_t }}$$\n",
    "\n",
    "\n",
    "Below you can read the corresponding matricial implementation for multiple documents.\n",
    "\n",
    "### Parser\n",
    "Using the CountVectorizer class of Scikit-Learn, try the different parser options by generating unigrams and bigrams with different stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Default values for arguments for CountVectorizer on vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "#Defined some arguments of CountVectorizer on bigram_vectorizer\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', \n",
    "                                    min_df=1, stop_words = {'the', 'is'})\n",
    "#simple list of strings, represents a document\n",
    "corpus = ['This is the first document.',\n",
    "'This is the second second document.',\n",
    "'And the third one.',\n",
    "'Is this the first document?', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'text', 'document', 'to', 'analyze']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates a vector with the words of the string ,only includes the words with 2 or more characters\n",
    "uni_analyze = vectorizer.build_analyzer()\n",
    "uni_analyze(\"This is a text document to analyze.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#Counts each word ocurrence in the list corpus,returns a sparse matrix with the count of the words\n",
    "tf_uni = vectorizer.fit_transform(corpus).toarray()\n",
    "#Prints the corresponding words to the columns of the sparse matrix\n",
    "print(vectorizer.get_feature_names())\n",
    "#Added line to see the matrix, each row represents a line in the document, each column represents the count of each word found in the document\n",
    "print(tf_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'a',\n",
       " 'text',\n",
       " 'document',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'this a',\n",
       " 'a text',\n",
       " 'text document',\n",
       " 'document to',\n",
       " 'to analyze']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''Separates the words, ignores stop word \"the\" and \"is\",it also reads the document one time separating each of the words,\n",
    "then a second time separating in 2 words due to the n-gram_range(1,2)''' \n",
    "\n",
    "\n",
    "bi_analyze = bigram_vectorizer.build_analyzer()\n",
    "bi_analyze(\"This is a text document to analyze.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'and third', 'document', 'first', 'first document', 'one', 'second', 'second document', 'second second', 'third', 'third one', 'this', 'this first', 'this second']\n",
      "\n",
      "[[0 0 1 1 1 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 1 0 0 0 2 1 1 0 0 1 0 1]\n",
      " [1 1 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#Creates another sparce matrix using the bigram_vectorizer method, this one is bigger than the first method because the additional\n",
    "#2-gram sparsing, it searches the document in 1-grams first then the bigrams\n",
    "tf_bi = bigram_vectorizer.fit_transform(corpus).toarray()\n",
    "print(bigram_vectorizer.get_feature_names())\n",
    "print()\n",
    "print(tf_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.vocabulary_.get('document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF and the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf:\n",
      " [[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "\n",
      "idf:\n",
      " [1.38629436 0.28768207 0.69314718 0.28768207 1.38629436 1.38629436\n",
      " 0.         1.38629436 0.28768207]\n",
      "\n",
      "tfidf:\n",
      " [[0.         0.28768207 0.69314718 0.28768207 0.         0.\n",
      "  0.         0.         0.28768207]\n",
      " [0.         0.28768207 0.         0.28768207 0.         2.77258872\n",
      "  0.         0.         0.28768207]\n",
      " [1.38629436 0.         0.         0.         1.38629436 0.\n",
      "  0.         1.38629436 0.        ]\n",
      " [0.         0.28768207 0.69314718 0.28768207 0.         0.\n",
      "  0.         0.         0.28768207]]\n",
      "\n",
      "docnorms:\n",
      " [0.85366032 2.81700748 2.40113227 0.85366032]\n"
     ]
    }
   ],
   "source": [
    "#calculates the sum of each column of the sparse matrix\n",
    "termCollFreq = np.sum(tf_uni != 0, axis = 0)\n",
    "#calculates the sum of each row\n",
    "docLen = np.sum(tf_uni, axis = 1)\n",
    "\n",
    "#calculates idf by dividing the number of columns by the sum of each column and doing the log of the result.\n",
    "idf = np.log(np.size(corpus)/termCollFreq)\n",
    "\n",
    "idf_rows = np.dot(np.ones((np.size(corpus),1)), idf.reshape(1,np.size(idf)))\n",
    "tfidf = tf_uni*idf_rows\n",
    "\n",
    "#Calculates the Norm of each row of the matrix, in other words, each document.\n",
    "docNorms = np.sqrt(np.sum(np.power(tfidf,2), axis = 1))\n",
    "        \n",
    "print(\"\\ntf:\\n\", tf_uni)\n",
    "print(\"\\nidf:\\n\", idf)\n",
    "print(\"\\ntfidf:\\n\", tfidf)\n",
    "print(\"\\ndocnorms:\\n\", docNorms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])**np.array([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = 'document'\n",
    "#checks each column of the features and only keeps the ones that are equal to the query\n",
    "query_vector = vectorizer.transform([query]).toarray()\n",
    "#Norm of the created vector\n",
    "queryNorm = np.sqrt(np.sum(np.power(query_vector, 2), axis = 1))\n",
    "\n",
    "#Scores the query_vector for each document.\n",
    "#The second document has the same frequencie of the word document as the first and forth, but due to a bigger docNorm because,\n",
    "#this document has more words and the score is lower.\n",
    "doc_scores = np.dot(query_vector, tfidf.T)/(docNorms*queryNorm)\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index\n",
    "The matricial implementation is not scalable because it computes the similarity for all documents in the collection. However, one should only compute the similarity for the documents containing the query words. This is where the inverted index comes to our rescue.\n",
    "\n",
    "Read the inverted index implementation presented next. Describe in your own words how the cosine similarity should be implemented with the inverted index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Creating the posting list for token \" and \"\n",
      "[(1, 2)]\n",
      "==== Creating the posting list for token \" document \"\n",
      "[(1, 0), (1, 1), (1, 3)]\n",
      "==== Creating the posting list for token \" first \"\n",
      "[(1, 0), (1, 3)]\n",
      "==== Creating the posting list for token \" is \"\n",
      "[(1, 0), (1, 1), (1, 3)]\n",
      "==== Creating the posting list for token \" one \"\n",
      "[(1, 2)]\n",
      "==== Creating the posting list for token \" second \"\n",
      "[(2, 1)]\n",
      "==== Creating the posting list for token \" the \"\n",
      "[(1, 0), (1, 1), (1, 2), (1, 3)]\n",
      "==== Creating the posting list for token \" third \"\n",
      "[(1, 2)]\n",
      "==== Creating the posting list for token \" this \"\n",
      "[(1, 0), (1, 1), (1, 3)]\n"
     ]
    }
   ],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "#Creates a dictionary whit the posting lists and the feature names\n",
    "i = 0\n",
    "inverted_index = dict()\n",
    "for token in features:\n",
    "    print(\"==== Creating the posting list for token \\\"\", token, \"\\\"\")\n",
    "    docs_with_token = np.where(tf_uni[:,i] != 0)\n",
    "    len = np.size(docs_with_token,1)\n",
    "    \n",
    "    postings_matrix = np.concatenate([tf_uni[docs_with_token,i], docs_with_token])\n",
    "    postings_list = list(map(tuple, postings_matrix.T))\n",
    "    inverted_index[token] = postings_list\n",
    "    # each line shows the frequencie of the word and the the correspondent document where the word was found\n",
    "    # this is used to map the information on the database.\n",
    "    print(postings_list)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the Vector Space Model, run the experiments of section 4.\n",
    "\n",
    "We advice you to use an external Python IDE for editing more complex implementations. **The Notebook should be used as a notebook, not as an IDE**. Your implementations should be organized on external classes as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RetrievalModelsMatrix as b\n",
    "\n",
    "aa = b.RetrievalModelsMatrix(tf_uni, vectorizer)\n",
    "#unfinished in retrieval methods \n",
    "#aa.score_lmd(\"document\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         0.66666667 0.5       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import MeanAveragePrecision as m\n",
    "bb=m.MeanAveragePrecision(tf_uni,vectorizer)\n",
    "\n",
    "print(bb.cumulative_pscore('second'))  #Will be used to determine the precision recall curve\n",
    "bb.recall('second')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7a6f71cb00>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGeCAYAAACO+utRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt4lOWB///P5AAhYDiFBJNJMhIJEAgkw1GwUhCxBIFNUBcX1AgVqLV+v8WuWq2tossibeN2d4vEloKV/rRIEqhUxWXFAxardMLJCKIkJJMEQpBDQshx7u8f/JiagjBRJpMneb+ua67LZ+aemc/cJJmPz3PPPDZjjBEAAIAFBQU6AAAAwNdFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJYVEugA/tS1a1f169cv0DEAAEArHDt2TPX19T6N7dBFpl+/fnK73YGOAQAAWsFut/s8lkNLAADAsigyAADAsigyAADAsjr0GhkAANo7Y4z30lnYbDYFBV2ZfSkUGQAAAsDj8aiyslInT57sVCXmvNDQUMXHx6tLly7f6HEoMgAABMDhw4cVFBQkh8Oh0NDQQMdpU8YYHT9+XCUlJbr22mu/0WNRZAAAaGMej0d1dXUaOHCgQkI651tx37599cUXX8jj8Xyjw0ws9gUAoI2dP5Rks9kCnCRwzr/2b3pYjSIDAAAsiyIDAEA7ZrPZVFNTE+gYrVZcXKznn3/e789DkQEAAFdchykyDzzwgBwOh2w2m/bt2/eV455++mklJiYqMTFRjz/+uM+3AQDQkeTl5Wnw4MG67rrr9NRTT3mvf+ONN+R0OjV8+HBNnDhRhYWF3tvWrFmj1NRUjRgxQqNGjVJxcbGKi4sVGRnpHVNTU9NiTY7NZtO///u/a8yYMRowYIC2bt2qH//4x0pLS9PQoUP18ccfe8e++OKLGjt2rJxOpyZOnOh9P1+7dq1uvvlm3XHHHUpJSdGoUaN06NAhSdLixYtVWFio1NRUzZw502/zJeNn77zzjiktLTUJCQlm7969XzkmOTnZ1NTUmLq6OjNy5EjzxhtvXPa2y4mNjb1irwMAgCulqanJFBYWmqamphbXHz161PTp08fs37/fGGPMM888YySZw4cPm759+5o9e/YYY4xZt26dGTp0qDHGmG3btpnExERTXl5ujDHmzJkz5syZM6aoqMj07dvX+9jV1dXmy2/7ksx///d/G2OMWb9+vQkPDzebN2/2Pu8dd9xhjDFm+/btJj093dTV1RljjHn33XfN8OHDjTHGrFmzxvTs2dMUFxcbY4x5+OGHzcKFC725Ro4c2eo5MKZ1799+3yNzww03XPYsln/84x+VlZWl7t27q2vXrpo/f75eeumly94GAEBH8sEHH8jpdGrQoEGSpIULF0qSdu/erdTUVKWkpEiS5s6dK7fbrYqKCv35z3/WXXfdpauvvlqSFB4ervDwcJ+e75//+Z8lSU6nU0FBQZo+fbokaeTIkd49K5s2bdLu3bs1duxYpaam6gc/+IGOHTumhoYGSdL111+vhIQESdJ1112nzz///EpMhc/axYfXS0pKNHHiRO+2w+HQhg0bLntbIKzeXqRlr30SsOcHINkk/fCmJH1/0jf7Ii2gvTFf8VFkY8xFP6p9qY9vh4SEqLm52btdV1d3wZiwsDBJUnBwsLp27eq9Pjg4WE1NTd7nnj9/vpYuXXrR5zn/GP94v7bSLoqM1PIf4x//IS9125dlZ2crOzvbu+2PVd7xfcJ14+CoK/64AHz3ZuFR7XGfDHQM4Iq77rrrtGDBAn366adKSkrSb3/7W0lSWlqadu3apU8++URDhgzRyy+/LLvdrv79+2vGjBmaP3++Fi5cqP79+6u2tlaS1L9/fzU1NenAgQMaNGiQfv/733+tTDNmzNBdd92le++9V3FxcfJ4PHK5XBo1atQl7xcREaFTp059redsjXZRZOLj41VcXOzdPnz4sOLj4y972z9asmSJlixZ4t2+3CGtr+Om5GjdlBx9xR8XgO8SH30t0BEAv4iKitLzzz+vGTNmqG/fvrr11lslSb1799aLL76ouXPnqrm5Wb169dL69eslnVvC8ZOf/ERTp06VzWZTly5dtGHDBiUkJOg///M/NW3aNNntdk2bNu1rZbrhhhu0bNkyzZo1S83NzWpsbNT06dMvW2SGDx+uQYMGadiwYRowYID+9Kc/fa3nvxybudQujivI4XBo8+bNGjZs2AW3vf3227r//vv117/+VSEhIZowYYKefvppfec737nkbZdjt9vldrv98XIABFDio69pypAo5dx56T+kQHvV3Nzs3esSHBwc6DgBcak5aM37t98X+37/+9/3BpoyZYr35FDp6enauXOnJOnb3/62br/9dqWkpGjIkCGaOnWqt6hc6jYAANC5tdkemUBgjwzQMbFHBlbHHhkL7ZEBAADwF4oMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAACwLIoMAABt7PypdzrwN6Bc1vnXfqnzRfmiXZyiAACAziQoKEhhYWEqKytTdHS0QkNDAx2pTRljdPz4cYWGhioo6JvtU6HIAAAQAAkJCaqsrFRxcXGn3DMTGhr6ledObA2KDAAAARAUFKT+/fsrOjpaxphOVWZsNts33hNzHkUGAIAAstls33idSGfGYl8AAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZFBkAAGBZfi8yBw8e1Pjx45WUlKQxY8aosLDwgjFnzpzRPffco5SUFA0aNEiPPPKIjDGSpLffflvh4eFKTU31Xs6ePevv2AAAwAL8XmQWLVqkhQsX6tNPP9VDDz2kBQsWXDBm2bJlkqQ9e/Zo3759Kigo0IYNG7y3Jycna9euXd5Lt27d/B0bAABYgF+LTGVlpVwul+bNmydJmj17toqKilRcXNxi3O7duzVt2jTZbDaFhoZq6tSpevHFF/0ZDQAAdAB+LTKlpaWKiYlRSEiIJMlmsyk+Pl4lJSUtxo0ePVrr169XQ0ODqqurlZ+f36LsHDhwQE6nU6NHj9bKlSv9GRkAAFiI3w8t2Wy2Ftvn17582cMPP6y4uDiNGTNGM2fO1Pjx4xUaGipJcjqdcrvdcrlcys/P16pVq7R+/fqLPld2drbsdrv3UlNTc+VfEAAAaDf8WmTi4uLkdrvV1NQk6VyJKS0tVXx8fItxYWFhevbZZ7Vr1y5t27ZNffr0UXJysiQpIiJCPXv2lCTZ7Xbdcccdeu+99y76fEuWLJHb7fZeevTo4cdXBwAAAs2vRSYqKkppaWlat26dJCk3N1cOh0MOh6PFuNOnT6u2tlaSVFRUpOeee04PPvigJKmiokIej0eSVF1drc2bNystLc2fsQEAgEWE+PsJcnJylJWVpWXLlikiIkIvvPCCJCk9PV1Lly7VqFGjdOjQId1+++0KCQlRSEiInn32WaWmpko6V36ee+45hYSEqKmpSbfddpvuuecef8cGAAAWYDMXW7TSQdjtdrnd7kDHAHCFJT76mqYMiVLOnaMCHQWAH7Tm/Ztv9gUAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJZFkQEAAJbl9yJz8OBBjR8/XklJSRozZowKCwsvGHPmzBndc889SklJ0aBBg/TII4/IGOO9ffXq1Ro4cKASExO1cOFCNTU1+Ts2AACwAL8XmUWLFmnhwoX69NNP9dBDD2nBggUXjFm2bJkkac+ePdq3b58KCgq0YcMGSVJRUZEef/xxbd++XZ999pmOHDmi1atX+zs2AACwAL8WmcrKSrlcLs2bN0+SNHv2bBUVFam4uLjFuN27d2vatGmy2WwKDQ3V1KlT9eKLL0qSNmzYoIyMDEVHR8tms2nx4sV66aWX/BkbAABYhF+LTGlpqWJiYhQSEiJJstlsio+PV0lJSYtxo0eP1vr169XQ0KDq6mrl5+d7y05JSYkSEhK8Yx0OxwX3BwAAnZPfDy3ZbLYW219e+3Leww8/rLi4OI0ZM0YzZ87U+PHjFRoaetHHuNj9z8vOzpbdbvdeampqrsArAAAA7ZVfi0xcXJzcbrd3ca4xRqWlpYqPj28xLiwsTM8++6x27dqlbdu2qU+fPkpOTpYkxcfHtzgUdfjw4Qvuf96SJUvkdru9lx49evjnhQEAgHbBr0UmKipKaWlpWrdunSQpNzdXDodDDoejxbjTp0+rtrZW0rnFvc8995wefPBBSefW1eTn5+vo0aMyxmjVqlWaM2eOP2MDAACL8PuhpZycHOXk5CgpKUnLly/3fuIoPT1dO3fulCQdOnRIqampSk5O1qxZs/Tss88qNTVVkjRgwAA9+eSTmjBhghITExUVFXXRTz4BAIDOx2YutejE4ux2u9xud6BjALjCEh99TVOGRCnnzlGBjgLAD1rz/s03+wIAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMuiyAAAAMsKac3giooKFRUVqampyXvdDTfccMVDAQAA+MLnIvNv//Zv+vnPf64BAwYoODhYkmSz2fThhx9e8n4HDx7U3XffraqqKvXq1Utr165VcnJyizF1dXVavHix/va3v8kYowEDBuh3v/udIiMj9fbbbys9PV1JSUne8Tt27FC3bt1a8zoBAEAH5HOR+d3vfqfPPvtMkZGRrXqCRYsWaeHChcrKytKGDRu0YMEC7dixo8WYnJwc1dTUaM+ePbLZbLr33nu1YsUKrVixQpKUnJysnTt3tup5AQBAx+fzGpn+/fu3usRUVlbK5XJp3rx5kqTZs2erqKhIxcXFF4ytra1VY2OjmpqaVFNTI7vd3qrnAgAAnY/PRebmm2/Wgw8+KJfLpcLCQu/lUkpLSxUTE6OQkHM7fmw2m+Lj41VSUtJi3KJFixQREaGoqChFR0fr1KlTuv/++723HzhwQE6nU6NHj9bKlStb8/oAAEAH5vOhpTVr1kiS8vLyvNfZbDYdOnTokvez2Wwtto0xF4zZunWrbDabjhw5oqCgIGVlZWnp0qV64okn5HQ65Xa71bNnT7ndbqWnpysyMlK33377BY+TnZ2t7Oxs73ZNTY2vLw8AAFiQz3tkioqKLrhcrsTExcXJ7XZ7P+VkjFFpaani4+NbjFu1apUyMjIUFhamLl26aO7cudq2bZskKSIiQj179pQk2e123XHHHXrvvfcu+nxLliyR2+32Xnr06OHrywMAABbUqu+R2blzp5555hmtWLFCf/vb3y47PioqSmlpaVq3bp0kKTc3Vw6HQw6Ho8W4AQMGaMuWLTLGyBijzZs3a9iwYZLOfeTb4/FIkqqrq7V582alpaW1JjYAAOigfC4yv/nNb5SZmamKigqVl5crMzNTv/3tby97v5ycHOXk5CgpKUnLly/X6tWrJUnp6eneTyI98cQTOnXqlIYOHaphw4apqqpKTz31lKRz5SclJUUjRozQuHHjdNNNN+mee+75Oq8VAAB0MDZzsUUrFzF8+HD97//+r/r16ydJOnbsmG688Ubt2bPHrwG/CbvdLrfbHegYAK6wxEdf05QhUcq5c1SgowDwg9a8f7fq0NL5EnP+v/9xIS8AAEBb8rnIXHvttXrsscdUXl6uiooKPfnkk0pMTPRnNgAAgEvyucisWrVKn3/+uYYPH67hw4dr//79WrVqlT+zAQAAXJLP3yMTFRWll19+2Z9ZAAAAWuWyReb999/XhAkT9Nprr1309vT09CseCgAAwBeXLTJr167VhAkT9POf//yC22w2G0UGAAAEzGWLzG9+8xtJ8n7TLgAAQHvh82LfV199VadPn5Yk/eIXv9Ctt96qjz/+2G/BAAAALsfnIvPYY48pIiJCu3fv1rp163TTTTdp8eLF/swGAABwST4XmZCQc0eh3nzzTS1cuFCLFi3SmTNn/BYMAADgcnwuMs3Nzfrggw+Um5urSZMmSZIaGxv9FgwAAOByfC4yTz/9tBYvXqzrr79eQ4YM0YEDBzRw4EB/ZgMAALgkn78Qb8aMGZoxY4Z3e9CgQcrLy/NLKAAAAF9ctsi88soruu2227Ry5cqL3n7fffdd8VAAAAC+uGyR2bdvn2677TZ99NFHbZEHAADAZ5ctMk8++aQkac2aNX4PAwAA0Bo+L/b92c9+puPHj3u3q6qqvCUHAAAgEHwuMps2bVLfvn2925GRkdq4caNfQgEAAPjC5yJjjLngOr5HBgAABJLPRSYpKUnZ2dkyxsjj8eiXv/ylBg8e7M9sAAAAl+RzkfnVr36lzZs3q1u3burevbveeOMN/dd//Zc/swEAAFySz1+IFxMTo7feest7fqXu3bv7LRQAAIAvWnWupV/96ld65JFH1L17d33++ed66623/JkNAADgknzeI/ODH/xAjY2N2r59uySpb9++mjNnDl+UBwAAAsbnIvOXv/xFu3btUlpamiSpV69eamho8FswAACAy/H50FJYWFiL7ebmZnk8niseCAAAwFc+F5nhw4frD3/4g4wxKi4u1n333acbbrjBn9kAAAAuyecik52drXfffVcVFRUaO3asPB6PVqxY4c9sAAAAl+TTGpnm5mZt2bJFOTk5ysnJ8XcmAAAAn/i0RyY4OFjZ2dn+zgIAANAqPh9aGjVqlHbs2OHPLAAAAK3i88ev3333Xf36179WUlKSevTo4b3+ww8/9EswAACAy/GpyOzbt08/+clPdOLECQ0cONDfmQAAAHxy2SKzcuVKPfbYY0pKStKBAwe0Zs0aZWRktEU2AACAS7rsGpmVK1dq7969+utf/6r33ntPv/zlL9siFwAAwGVdtsiEhobKbrdLklJSUrxnvwYAAAi0yx5aqq+v1yeffCJjzEW3k5OT/ZsQAADgK1y2yNTW1io9Pb3Fdee3bTabDh065J9kAAAAl3HZIlNcXNwGMQAAAFrP5y/EAwAAaG8oMgAAwLL8XmQOHjyo8ePHKykpSWPGjFFhYeEFY+rq6pSVlaWUlBQNGzZMM2fOVFVVlff21atXa+DAgUpMTNTChQvV1NTk79gAAMAC/F5kFi1apIULF+rTTz/VQw89pAULFlwwJicnRzU1NdqzZ4/27dun6OhorVixQpJUVFSkxx9/XNu3b9dnn32mI0eOaPXq1f6ODQAALMCvRaayslIul0vz5s2TJM2ePVtFRUUXXUBcW1urxsZGNTU1qaamxvvdNRs2bFBGRoaio6Nls9m0ePFivfTSS/6MDQAALMKvRaa0tFQxMTEKCTn34Sibzab4+HiVlJS0GLdo0SJFREQoKipK0dHROnXqlO6//35JUklJiRISErxjHQ7HBfcHAACdk98PLdlsthbb579I78u2bt0qm82mI0eOqKKiQr169dLSpUsv+hgXu/952dnZstvt3ktNTc0VeAUAAKC98muRiYuLk9vt9i7ONcaotLRU8fHxLcatWrVKGRkZCgsLU5cuXTR37lxt27ZNkhQfH9/iUNThw4cvuP95S5Yskdvt9l569OjhnxcGAADaBb8WmaioKKWlpWndunWSpNzcXDkcDjkcjhbjBgwYoC1btsgYI2OMNm/erGHDhkk6t64mPz9fR48elTFGq1at0pw5c/wZGwAAWITfDy3l5OQoJydHSUlJWr58ufcTR+np6dq5c6ck6YknntCpU6c0dOhQDRs2TFVVVXrqqacknSs5Tz75pCZMmKDExERFRUVd9JNPAACg87GZSy06sTi73S632x3oGACusMRHX9OUIVHKuXNUoKMA8IPWvH/zzb4AAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCyKDIAAMCy/F5kDh48qPHjxyspKUljxoxRYWHhBWOWL1+u1NRU7yUiIkJLliyRJL399tsKDw9vcfvZs2f9HRsAAFhAiL+fYNGiRVq4cKGysrK0YcMGLViwQDt27Ggx5pFHHtEjjzwiSWpoaFBMTIzmzp3rvT05OVk7d+70d1QAAGAxft0jU1lZKZfLpXnz5kmSZs+eraKiIhUXF3/lfTZu3Ci73a6RI0f6MxoAAPgG6puaAx1Bkp+LTGlpqWJiYhQScm7Hj81mU3x8vEpKSr7yPqtXr9aCBQtaXHfgwAE5nU6NHj1aK1eu9GdkAADwFRqbPXpr/1F9//9zafTTW3XqbGOgI/n/0JLNZmuxbYz5yrGlpaXavn27XnrpJe91TqdTbrdbPXv2lNvtVnp6uiIjI3X77bdfcP/s7GxlZ2d7t2tqaq7AKwAAoPMyxujj8tPKdbn1p13lOn6mQZI05po+qqqpV89uoQHN59ciExcXJ7fbraamJoWEhMgYo9LSUsXHx190/Jo1azRz5kz16dPHe11ERIT3v+12u+644w699957Fy0yS5Ys8S4SPj8eAAC0XsWps9pYUK48l1sHK8/tGLgmsruyxjv0T2mxiusTHuCE5/i1yERFRSktLU3r1q1TVlaWcnNz5XA45HA4LhhrjNHatWv1/PPPt7i+oqJC0dHRCgoKUnV1tTZv3nzBoScAAPDN1dQ36Y19R5Rf4NZfPj8uY6Re4aG6c1yCMp2xSo3rdcGRlkDz+6GlnJwcZWVladmyZYqIiNALL7wgSUpPT9fSpUs1atQoSdJbb70lY4xuvPHGFvfPzc3Vc889p5CQEDU1Nem2227TPffc4+/YAAB0Cs0eo+2fVSnf5daWj4/qbGOzQoNtujm5vzKcsZo0KEpdQtrv187ZzKUWrVic3W6X2+0OdAwAV1jio69pypAo5dw5KtBRAMv6pOK08gvKtLGgTJXV9ZIkZ3wvZTrtumX41eoV3iVg2Vrz/u33PTIAAKB9qDxdp027ypVXUKZPKk5LkuL6dNMDNw5URlqsronsHuCErUeRAQCgAzvb0Kw3C48o11Wm7QePyWOkq8JCdMeYOGU67RqV0LvdrXtpDYoMAAAdjMdj9EHRceW5yvT63gqdaWhWSJBNkwdHKdNp1+TBUQoLDQ50zCuCIgMAQAfxWWW18lzn1r2Un6qTJI2w91RGWqxmjIhR3x5dA5zwyqPIAABgYVU19Xp1d7nyC8q0x31KkhTTM0zfn5SojDS7ro3qEeCE/kWRAQDAYuoam/W/n1Qqz+XWO58eU5PHqHuXYN020q5Mp11jr+mjoCDrrntpDYoMAAAWYIzRR8UnlF/g1uY9Faqua1KQTfrWwH7KdMZqanJ/devSMda9tAZFBgCAdqyo6ozyXW7l7ypT6RdnJUnJV0co0xmrmSNiFBURFuCEgUWRAQCgnTlZ26BX91Qoz+VWQclJSVLUVV216IYBynDGanD/iMs8QudBkQEAoB2ob2rWtv3HlF/g1lv7K9XYbNQtNFgZabHKdMZqfGKkgjvJupfWoMgAABAgxhgVlJ5UnuvcupeTtY2y2aQJiZHKSIvVd4b1V/euvFVfCrMDAEAbK/2iVvkFZcovKFNR1RlJUlJ0Dy2emKhZqTG6ume3ACe0DooMAABt4NTZRr2+t0J5rjJ9WPyFJCmyRxfNn3CNMp2xGhoTYelTBQQKRQYAAD9pbPbo3U+PKa+gTP9TeFQNTR51DQnSLcOv1mynXd8aGKmQ4KBAx7Q0igwAAFeQMUb7yk4r1+XWq7vLdfxMgyRp7DV9lOmM1bSUqxURFhrglB0HRQYAgCug/ORZbdxVpjxXmT6rrJEkDYjsrnsmODQrNVZxfcIDnLBjosgAAPA11dQ36fW9FcovKNOOQ8dljNQ7PFR3XZegTKddI+w9WffiZxQZAABaodljtP2zKuW53Nry8RHVNXrUJThI3xnaXxlpsfr2oCh1CWHdS1uhyAAA4INPKk4rz+XWpl3lqqyulySNTOitTGespqdcrV7hXQKcsHOiyAAA8BUqT9dp065y5brc2n+kWpIU3ydc/+fGgcpIi5UjsnuAE4IiAwDAl9Q2NOnNj48qr6BM2w8ek8dIEWEh+pex8cpMi9XIhN6se2lHKDIAgE7P4zH64NBx5brK9Ma+Cp1paFZIkE2TB0drtjNWkwZHKSw0ONAxcREUGQBAp3XwaLXyCsq0saBMFafqJEkj7D2V6bTrluFXq2+PrgFOiMuhyAAAOpWqmnr9aVe58gvKtLfslCSi8keQAAAWNUlEQVQptlc3fX9SojLS7Lo2qkeAE6I1KDIAgA6vrrFZWz85qjxXmd759JiaPUY9uobo9lF2ZaTZNfaaPgoKYt2LFVFkAAAdksdjtPPwCeW53PrzngpV1zcpOMimbw2MVKbTrpuGRKtbF9a9WB1FBgDQoRRVnVG+y628gjK5T5yVJA2NiVBGWqxmpsYo6qqwACfElUSRAQBY3okzDdq8p1x5BWUqKDkpSYqO6KpFEwcoM82uQf2vCnBC+AtFBgBgSfVNzdq2/5jyXG5tO1Cpxmaj8C7BykyLVabTrusS+yqYdS8dHkUGAGAZxhi5Sk4qv8CtV3dX6NTZRtls0vXXRiojLVY3D+2v7l15a+tM+NcGALR7JcdrlV9QpvwCt4qP10qSkqJ76L5vJ2pWaqz692TdS2dFkQEAtEunzjbqtb0VynO59VHxCUlSZI8uWnD9NcpIi9XQmAhOFQCKDACg/Whs9uidA8eUX1Cm//nkqBqaPOoaEqQZI2KU6YzVt66NVEhwUKBjoh2hyAAAAsoYo71lp5TnKtOru8t1/EyDJGncgD7KTLNrWkp/XRUWGuCUaK8oMgCAgCg7eVYbC8qUX1CmzyprJEkD+nXX/Ouv0azUGNl7hwc4IayAIgMAaDM19U16fW+F8lxl+qDouIyReoeH6u7rEpTptGu4vSfrXtAqFBkAgF81NXu0/bMq5ReUacvHR1TX6FGX4CBNG9ZfGWl2TUzqpy4hrHvB10ORAQD4RWH5aeW53Nq0u1zHquslSaMSeivTadf0lKvVM5x1L/jmKDIAgCvm6Ok6bdpVpjxXmfYfqZYkJfQN1/+dMlAZabFK6Ns9wAnR0VBkAADfSG1Dk7Z8fER5rjK9/1mVPEaKCAvR3LHxynTGyhnfm3Uv8Bu/F5mDBw/q7rvvVlVVlXr16qW1a9cqOTm5xZjly5fr5Zdf9m4fOnRI3/3ud5WdnS1JWr16tZYvXy6Px6Mbb7xRK1euVEgIHQwAAqXZY/TBoePKdbn1xr4jqm1oVkiQTTcOiVZmWqwmD4lS15DgQMdEJ2Azxhh/PsHkyZN11113KSsrSxs2bNAvf/lL7dix4yvHNzQ0KCYmRlu2bNHIkSNVVFSkCRMmqKCgQFFRUZo1a5amT5+uRYsWXfa57Xa73G73lXw5ANqBxEdf05QhUcq5c1Sgo3Q6nx6tVp6rTJt2laniVJ0kaURcL812xuqW4THq071LgBOiI2jN+7dfd2tUVlbK5XLpzTfflCTNnj1b999/v4qLi+VwOC56n40bN8put2vkyJGSpA0bNigjI0PR0dGSpMWLF2vFihU+FRkAwDdXVVOvP+0qV16BW/vKTkuSYnt10/2TrlWGM1aJ/XoEOCE6M78WmdLSUsXExHgPA9lsNsXHx6ukpOQri8zq1au1YMEC73ZJSYkSEhK82w6HQyUlJf6MDQCdXl1js/6n8KjyC8r0zqfH1Owx6tE1RP88Kk4ZzliNcfRRUBDrXhB4fl9o8o8LvC51JKu0tFTbt2/XSy+99JWPcan7Z2dne9fVSFJNTU1r4wJAp+XxGH1U/IXyXGV6bW+FquubFBxk0w0DI5XptOum5GiFhbLuBe2LX4tMXFyc3G63mpqaFBISImOMSktLFR8ff9Hxa9as0cyZM9WnTx/vdfHx8SouLvZuHz58+Cvvv2TJEi1ZssS7bbfbr8wLAYAO7NCxGuUXnPvIdNnJs5KkYbERykiza+aIGPW7qmuAEwJfza9FJioqSmlpaVq3bp2ysrKUm5srh8Nx0cNKxhitXbtWzz//fIvrZ8+ereuvv14//elPFRUVpVWrVmnOnDn+jA0AHd6JMw16dU+58lxl2lV6UpLUPyJMiycmKtMZq6ToqwKcEPCN3w8t5eTkKCsrS8uWLVNERIReeOEFSVJ6erqWLl2qUaPOfergrbfekjFGN954Y4v7DxgwQE8++aQmTJggj8ejyZMnt1hDAwDwTX1Ts7btr1Suq0xvH6hUY7NReJdgZTpjNdtp17gBfRXMuhdYjN8/fh1IfPwa6Jj4+LXvjDFylZxUnsutzXsqdOpso4Js0oRrI5XpjNXNQ/srvAvfy4X2pd18/BoAEBglx2uVX1Cm/AK3io/XSpIGRV+l+76dqFmpserfMyzACYErgyIDAB3EqdpG/XlvhfIL3Pqo+IQkKbJHV333+muU4YxV8tURnCoAHQ5FBgAsrLHZo3cOHFNegVtbP6lUQ5NHYaFBmjkiRpnOWF1/baRCgoMCHRPwG4oMAFiMMUZ73KeUX1CmP+0u1xdnGiRJ1w3oqwxnrKYN66+rwkIDnBJoGxQZALCIspNntbGgTHkutz4/dkaSlNivuxZcf43+KS1Wsb26BTgh0PYoMgDQjlXXNer1fUeU53Lrg0NfSJL6dO+irPEOZTpjlRLbk3Uv6NQoMgDQzjQ1e7T9syrlucr0ZuER1TV61CU4SNNTrlZGWqwmDuqnUNa9AJIoMgDQLhhjVFhxWvmuMm3cVa6qmnpJ0mhHb2Wk2TU95Wr1DGfdC/CPKDIAEEBHT9dpY0GZ8gvKtP9ItSQpoW+47hyXpIy0WMX3DQ9wQqB9o8gAQBurbWjSlo+PKM9Vpvc/q5LHSD27hWru2HhlOu1yxvdi3QvgI4oMALSBZo/Rjs+PK6/ArTf2HVFtQ7NCg22aMiRamc5YTRocpa4hwYGOCVgORQYA/OjTo9XKdbm1qaBcR07XSZJS43pptjNWtwyPUe/uXQKcELA2igwAXGHHquv1p93lynO59XH5aUmSvXc3/WDytcpIi9WAfj0CnBDoOCgyAHAF1DU2683Co8p3ufXuwSo1e4yu6hqiOaPjlJEWq9GOPgoKYt0LcKVRZADga/J4jD4s/kL5rjK9trdC1fVNCg6yaWJSP2U6YzVlSLTCQln3AvgTRQYAWunzYzXKd537yHTZybOSpJTYnspIi9XM1BhF9uga4IRA50GRAQAffHGmQZv3lCvXVabdpSclSVf3DNPiiYnKdMYqKfqqACcEOieKDAB8hfqmZr31SaXyCsq0bX+lmjxG4V2CNdtpV6YzVuMG9FUw616AgKLIAMCXGGPkKjmhXFeZ/rynQqfONirIJk24NlKznXZNHRqt8C786QTaC34bAUDS4eNnlP//nyrg8PFaSdLg/lfp+5MSNSs1VtERYQFOCOBiKDIAOq1TtY3avLdc+a4y7Tx8QpLU76quuvdb1ygjza7kmIgAJwRwORQZAJ1KQ5NH73x6TPkFbm0trFRDs0dhoUGalRqjTKddExL7KiQ4KNAxAfiIIgOgwzPGaI/7lPJcbr26p0JfnGmQzSZdN6CvMtJiNS3lavXoyp9DwIr4zQXQYblP1GrTrnLlutw6dOyMJOnaqB767reu0T+lxiqmV7cAJwTwTVFkAHQo1XWNen3vEeUVuPXBoS8kSX26d1HWeIcynbFKie0pm42PTAMdBUUGgOU1NXv03mdVynOV6c2Pj6i+yaMuIUGannK1Mp2xuiGpn0JZ9wJ0SBQZAJZkjLSv7JTyC8q0aVe5qmrqJUljHH2U4YxVesrV6tktNMApAfgbRQaAJf3v/kq9WXhUkuToG667rktSRlqs4vqEBzgZgLZEkQFgOfbe3XSytlEzRlytTKddaXG9WPcCdFIUGQCWs3XJRBkjdQlh3QvQ2VFkAFgOC3cBnMdfAwAAYFkUGQAAYFkUGQAAYFkUGQAAYFkUGQAAYFkUGQAAYFkUGQAAYFkUGQAAYFkUGQAAYFkUGQAAYFl+LzIHDx7U+PHjlZSUpDFjxqiwsPCi49555x2NHj1aQ4cO1eDBg7Vjxw5J0tq1a9WrVy+lpqYqNTVVkyZN8ndkAABgEX4/19KiRYu0cOFCZWVlacOGDVqwYIG3pJxXXl6uu+++W6+//rqGDBmiuro61dXVeW+fMmWKNmzY4O+oAADAYvy6R6ayslIul0vz5s2TJM2ePVtFRUUqLi5uMW7lypWaN2+ehgwZIkkKCwtTr169/BkNAAB0AH4tMqWlpYqJiVFIyLkdPzabTfHx8SopKWkxrrCwUGfPntWUKVOUmpqqH/zgB6qtrfXe/s477yg1NVUTJkxgzwwAAPDy+6Elm83WYtsYc8GYxsZGvf3229q6dauuuuoqzZ8/X0888YRWrFihW265RbfffrvCw8P1ySefaOrUqbLb7Ro3btwFj5Odna3s7Gzvdnl5uex2+5V/URZUU1OjHj16BDpGu8F8tMR8/B1z0RLz0RLz8Xf+nItjx475PNavRSYuLk5ut1tNTU0KCQmRMUalpaWKj49vMS4hIUFpaWnq3bu3JGnOnDlasWKFJCkyMtI7bsiQIUpPT9f7779/0SKzZMkSLVmyxLttt9vldrv98dIsh7loifloifn4O+aiJeajJebj79rLXPj10FJUVJTS0tK0bt06SVJubq4cDoccDkeLcf/yL/+ibdu2qb6+XpL0xhtvaMSIEZKksrIy77ijR4/qrbfeUlpamj9jAwAAi/D7oaWcnBxlZWVp2bJlioiI0AsvvCBJSk9P19KlSzVq1CiNHz9eM2bMUGpqqkJCQjRs2DCtWrVKkvTrX/9amzZtUmhoqDwej374wx9q8uTJ/o4NAAAswO9FZtCgQRd83FqSXnvttRbbDz30kB566KELxi1btkzLli37Ws/95cNMnR1z0RLz0RLz8XfMRUvMR0vMx9+1l7mwmYutvgUAALAATlEAAAAsiyIDAAAsy/JFxpdzOeXn52v48OFKTU3V0KFD9dhjj130+2ysztfzWknnPqMfHR2tW2+9tQ0Tti1f5qMzncvrm573rCPxZS6WL1/u/blITU1VREREu1kTcKX5Mh91dXXKyspSSkqKhg0bppkzZ6qqqioAaf3Pl/k4c+aM7rnnHqWkpGjQoEF65JFHOuT7ygMPPCCHwyGbzaZ9+/Z95binn35aiYmJSkxM1OOPP96GCSUZi5s0aZJZs2aNMcaYV155xYwbN+6CMadPnzbNzc3GGGPq6+vN6NGjzaZNm9oyZpvwZS7Ou/XWW01WVpaZPXt2G6Vre77Mx5o1azr0HHyZL/NRVlZmEhISTGFhoTHGmLNnz5oTJ060Zcw20ZrfFWPO/d3o27ev2blzZxuka3u+zMd//Md/mNmzZxuPx2OMMea73/2u+dd//de2jNlmfJmPRx991GRlZRmPx2MaGhrM1KlTzfr169s4qf+98847prS01CQkJJi9e/d+5Zjk5GRTU1Nj6urqzMiRI80bb7zRZhktvUfG13M5XXXVVQoKOvdS6+rqVF9f793uKHydC0n6wx/+oOjoaE2cOLGNU7ad1sxHZ8B5z/7u6/xsbNy4UXa7XSNHjmyjlG2nNfNRW1urxsZGNTU1qaampkN+c7qv87F7925NmzZNNptNoaGhmjp1ql588cUAJPavG2644bL/zn/84x+VlZWl7t27q2vXrpo/f75eeumlNkpo8UNLvp7LSZL+8pe/aPjw4YqKitKNN96o6dOnt3Vcv/J1LsrLy5Wdna3ly5cHImabac3PRmc4l9eVOu9ZR9Can43zVq9erQULFrRVxDbl63wsWrRIERERioqKUnR0tE6dOqX7778/EJH9ytf5GD16tNavX6+GhgZVV1crPz+/0/6PUklJiRISErzbDofjkr9PV5qli4zk27mcJGn8+PHas2ePSktL9dFHH+m9995ri3htype5uPfee7VixYpOca4QX+bjlltu0eHDh7Vr1y799re/1Q9/+EN98MEHbRWxTbXmvGevvPKKdu7cqVOnTumJJ55oo4Rtx9e/G9K5N7bt27dr7ty5/o4VML7Mx9atW2Wz2XTkyBFVVFSoV69eWrp0aVtFbFO+zMfDDz+suLg4jRkzRjNnztT48eMVGhraVhHbnS/P2aV+n/zB0kXmy+dykvSV53L6sn79+mn69Ol65ZVX2ipmm/B1Lnbs2KEFCxbI4XDoRz/6kV5//XXdfPPNgYjsV77OR2RkpMLDwyW1PJdXR+PrfCQkJGj69Onq3bu3QkJCNGfOHH344YeBiOw3rf27sWbNGs2cOVN9+vRpy5htxtf5WLVqlTIyMhQWFqYuXbpo7ty52rZtWyAi+5Wv8xEWFqZnn31Wu3bt0rZt29SnTx8lJycHInLAxcfHt9gbdfjw4Uu+D19pli4yvp7L6cCBA/J4PJKk6upqbd68WcOHD2/ruH7l61x88cUXKi4uVnFxsX7xi19o2rRp2rJlSwAS+5ev89FZzuV1Jc571lH4OhfSuTextWvXdtjDSpLv8zFgwABt2bJFxhgZY7R582YNGzYsAIn9y9f5OH36tPewa1FRkZ577jk9+OCDbR23Xbjtttv0wgsv6MyZM6qvr9fvfvc7zZkzp+0CtNmyYj/Zv3+/GTdunBk4cKAZOXKk2bdvnzHGmGnTppmPPvrIGGPMU089ZYYMGWKGDx9uhg4dan72s595V953JL7MxZd19E/s+DIfP/7xj01ycrIZMWKESUlJMb/+9a8DGdmvfP35eOaZZ8zgwYPNsGHDzJw5c8zJkycDFdlvfJ2LrVu3GofD0SH/XnyZL/Nx/PhxM3v2bDNkyBCTnJxsbr31VnP8+PFAxvYbX+ajoKDADBw40AwZMsSkpKSY3NzcQEb2m/vuu8/Exsaa4OBgEx0dbRITE40xF/6uPPnkk+aaa64x11xzjfnxj3/cphk5RQEAALAsSx9aAgAAnRtFBgAAWBZFBgAAWBZFBgAAWBZFBgAAWBZFBkBAOBwODR48WKmpqRo0aJDfTpvxxBNP6Ec/+pGkc2c778hnfAc6o5BABwDQeW3YsEHDhg1TeXm5kpOTNXnyZI0ZMybQsQBYCHtkAARcTEyMBg0apMOHD0uSXnzxRY0dO1ZOp1MTJ07Uvn37vGOfeeYZpaSkaMSIERo3bpxqa2t15MgRTZo0SSNHjtTQoUP1wAMPtPn5XgAEBntkAATc/v37VVVVpW9/+9t6//339fLLL+vdd99V165d9d5772nu3LnavXu3XnjhBW3cuFHvv/++IiIidOLECXXt2lW9evXSq6++qh49eqi5uVmzZs1Sbm4uh5GAToAiAyBgbr31VtlsNh04cEDPPvus+vXrp5///OfavXu3xo4d6x137NgxNTQ0aPPmzfre976niIgISVLv3r0lSfX19Xr44Ye1fft2GWNUWVmp1NRUigzQCVBkAATM+TUyW7du1YwZMzR58mQZYzR//nwtXbrU58fJzs7W8ePH9de//lVhYWFasmSJ6urq/JgcQHvBGhkAATdlyhR973vf009+8hPNmDFDv//971VaWipJ8ng82rlzpyRp5syZeu6553T69GlJ0smTJ9Xc3KwTJ06of//+CgsL09GjR/XKK68E7LUAaFvskQHQLjz++OO69tpr9dOf/lTLli3TrFmz1NzcrMbGRk2fPl2jRo3SnXfeqfLycl133XUKDQ1VeHi4tm7dqgceeEC33XabUlNTFRsbqylTpgT65QBoI5z9GgAAWBaHlgAAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZAAAgGVRZAAAgGX9P3j93NPTKhkBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bb.pr_curve('document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval Models\n",
    "\n",
    "In this section you will implement three of the most popular retrieval model. After finishing each retrieval model implementation, run the experiments of section 4 with the new model.\n",
    "\n",
    "### Language Model with Jelineck-Mercer Smoothing (20%)\n",
    "The family of Language Models for retrieval build on the density distribution of the terms over each document and the density distribution of terms over the collection of documents.\n",
    "\n",
    "There several ways of avoiding the zero probabilities problem with term smoothing.  The Jelineck-Mercer smoothing model uses a mixture of probabilities between the document model $M_d$ and the corpus model $M_c$:\n",
    "\n",
    "$$p(q|d,C)= \\lambda \\cdot p(q|M_d) + (1-\\lambda)\\cdot p(q|M_c)$$\n",
    "\n",
    "Implement the LMJM retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMJM model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the LMJM retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMJM model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model with Dirichlet Smoothing (20%)\n",
    "Another way of avoiding the zero probabilities problem is with the Dirichlet smoothing model that uses a mixture of frequencies between the term document frequencies $f_{t,c}$ and the term corpus frequency $\\mu \\cdot M_c(t)$:\n",
    "\n",
    "$$p(t|M_d, M_c)= \\frac{f_{t,d}+\\mu \\cdot M_c(t)}{|d| + \\mu}$$\n",
    "\n",
    "Implement the LMD retrieval model using the matricial definitions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMD model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the LMD retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMD model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM 25 (20%)\n",
    "\n",
    "The BM25 is model is an evolution of the tf-idf weighting based on a two Poisson distribution per term. It is obviously impossible to estimate each term distribution -- the approximation to the two Poisson distribution is given by the expression:\n",
    "\n",
    "$$RSV = \\sum q_t \\cdot \\frac{f_{t,d}(k_1 + 1)}{k_1 ((1-b) + b(\\frac{l_d}{l_avg})) + f_{t,d} }\\cdot IDF_t$$\n",
    "\n",
    "Implement the BM5 retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: BM25 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the BM25 retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: BM25 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the implemented Retrieval Models, run the experiments of section 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pseudo-Relevance Feedback (RM3) (20%)\n",
    "\n",
    "Using the RM3 Model, run the experiments of section 4.\n",
    "\n",
    "Implement the RM3 retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: RM3 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the RM3 retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: RM3 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the implemented RM3 model, run the experiments of section 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiments and Results (20%)\n",
    "The goal of this section is to compare experimentally the different retrieval models. In this section you must:\n",
    "- Load the Cranfield documents.\n",
    "- Run the implemented retrieval models\n",
    "- Plot the precision-recall curves.\n",
    "- Compute MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import simpleparser as parser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import collectionloaders\n",
    "import RetrievalModelsMatrix as model\n",
    "\n",
    "verbose = False\n",
    "bigrams = True\n",
    "\n",
    "### 1. Load the corpus\n",
    "cranfield = collectionloaders.CranfieldTestBed()\n",
    "\n",
    "### 2. Parse the corpus\n",
    "# Tokenize, stem and remove stop words\n",
    "def vsm_test(bigrams):\n",
    "    \n",
    "    \n",
    "    if not bigrams:\n",
    "        vectorizer = CountVectorizer()\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', \n",
    "                                        min_df=1, stop_words = {'the', 'is'})\n",
    "    \n",
    "    corpus = parser.stemCorpus(cranfield.corpus_cranfield['abstract'])\n",
    "    \n",
    "    ### 3. Create the model\n",
    "    # Compute the term frequencies matrix and the model statistics\n",
    "    tf_cranfield = vectorizer.fit_transform(corpus).toarray()\n",
    "    models = model.RetrievalModelsMatrix(tf_cranfield, vectorizer)\n",
    "    \n",
    "    ### 4. Run the queries over the corpus\n",
    "    i = 1\n",
    "    map_vsm = 0\n",
    "    precision_vsm = []\n",
    "\n",
    "    for query in cranfield.queries:\n",
    "        # Parse the query and compute the document scores\n",
    "        scores = models.score_vsm(parser.stemSentence(query))\n",
    "    \n",
    "        # Do the evaluation\n",
    "        [average_precision, precision, recall, thresholds] = cranfield.eval(scores, i)\n",
    "        map_vsm = map_vsm + average_precision\n",
    "        precision_vsm.append(precision)\n",
    "        \n",
    "        # Some messages...\n",
    "        if verbose:\n",
    "            plt.plot(recall, precision, color='silver', alpha=0.1)\n",
    "            print('qid =',i, 'VSM     AP=',average_precision)\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "    del models #deletes class instance\n",
    "    map_vsm = map_vsm/cranfield.num_queries\n",
    "    return map_vsm,recall,precision_vsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests the vsm retrieval model \n",
    "    \n",
    "First test without bigrams and second with bigrams\n",
    "\n",
    "Stores the values of the tests in a 3 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapl=[]\n",
    "recl=[]\n",
    "precl=[]\n",
    "for b in [False,True]:\n",
    "    new_map,new_recall,new_precision=vsm_test(b)\n",
    "    mapl.append(new_map)\n",
    "    recl.append(new_recall)\n",
    "    precl.append(new_precision)\n",
    "    \n",
    "ind=np.argmax(mapl)  #finds the index of the biggest map value\n",
    "map_vsm=mapl[ind]\n",
    "recall=recl[ind]\n",
    "precision_vsm=precl[ind]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compares the Precision-Recall curves of the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recl[0], np.mean(precl[0],axis=0), color='b', alpha=1,label=' normal ngrams')\n",
    "plt.plot(recl[1], np.mean(precl[1],axis=0), color='r', alpha=1,label=\" bigrams\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cranfield.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Show results\n",
    "print('MAP=',map_vsm)\n",
    "\n",
    "plt.plot(recall, np.mean(precision_vsm,axis=0), color='b', alpha=1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.fill_between(recall, \n",
    "                 np.mean(precision_vsm,axis=0)-np.std(precision_vsm,axis=0), \n",
    "                 np.mean(precision_vsm,axis=0)+np.std(precision_vsm,axis=0), facecolor='b', alpha=0.1)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall (MAP={0:0.2f})'.format(map_vsm))\n",
    "plt.savefig('results/prec-recall.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and discussion\n",
    "\n",
    "\n",
    "The following table summarizes the MAP and P10 results:\n",
    "\n",
    "| Retrieval Model | P10 | MAP   |\n",
    "|-----------------|-----|-------|\n",
    "| VSM             | ?   | {{map_vsm}} |\n",
    "| LMD             | ?   | ? |\n",
    "| LMJM             | ?   | ? |\n",
    "| BM25             | ?   | ? |\n",
    "\n",
    "![](results/prec-recall.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
