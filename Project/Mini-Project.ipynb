{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project: A Simple Search Engine from Scratch\n",
    "In this mini-project you will study the fundaments of IR.\n",
    "\n",
    "The mini-project is divided as follow:\n",
    "\n",
    "- **Week 1**: Study the provided notebook. Using the VSM retrieval model, run experiments *(section 4)* with the provided collection. Compute the metrics MAP, P10 and precision-recall curves.\n",
    "\n",
    "- **Week 2**: Implement the LMD and LMJM retrieval models and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "- **Week 3**: Implement the RM3 retrieval model and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "- **Week 4**: Implement the BM25 retrieval model and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "**Submission date: 15 October**\n",
    "\n",
    "## 1. Vector Space Model\n",
    "\n",
    "In the vector space model, documents are represented as a vector $d_j=(w_{d_j,1},w_{d_j,2}, ..., w_{d_j,n})$ of $n$ word frequencies -- most of the words are equal to 0. Queries are also represented as a vector of words $q_j=(w_{q_j,1},w_{q_j,2}, ..., w_{q_j,n})$. In the vector space model, each document word is weighted by their *tf-idf*\n",
    "\n",
    "$${tf-idf} = tf*\\frac{|D|}{log (df(w_a))}$$\n",
    "\n",
    "The vector space model is based on the cosine similarity, which measures the angle between the two vectors in the 1-unit sphere:\n",
    "\n",
    "$$cos(q,d) = \\frac{\\sum_t q_t\\cdot d_t}{\\sqrt{\\sum_t q^2_t}\\cdot \\sqrt{\\sum_t d^2_t }}$$\n",
    "\n",
    "\n",
    "Below you can read the corresponding matricial implementation for multiple documents.\n",
    "\n",
    "### Parser\n",
    "Using the CountVectorizer class of Scikit-Learn, try the different parser options by generating unigrams and bigrams with different stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#instancia um objeto com a função CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#instancia um objeto com a função CountVectorizer com parametros definidos\n",
    "#ngram_range: define os limites do tamanho dos n-grams a incluir na tokenização\n",
    "#stop_words: palavras a ignorar (são palavras comuns nos documentos, não oferecem nenhum valor adicional)\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', \n",
    "                                    min_df=1, stop_words = {'the', 'is'})\n",
    "\n",
    "#lista de documentos\n",
    "corpus = ['This is the first document.',\n",
    "'This is the second second document.',\n",
    "'And the third one.',\n",
    "'Is this the first document?', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instacia um objeto com uma função que lida com o pré-processamento e tokenização\n",
    "uni_analyze = vectorizer.build_analyzer()\n",
    "\n",
    "#pré-processa e tokeniza a string dada (ignora palavras com menos de duas letras e pontuação)\n",
    "uni_analyze(\"This is a text document to analyze.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instacia um objeto com uma matriz com informação acerca da frequencia das palavras em cada documento de corpus\n",
    "tf_uni = vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "#mostra os tokens correspondente a cada coluna da matriz\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print()\n",
    "\n",
    "#matriz das frequências de palavras por documento\n",
    "#cada linha é respeitante a um documento\n",
    "#cada coluna é respeitante a um token (palavra no caso uni-gram)\n",
    "print(tf_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "coln=vectorizer.get_feature_names()\n",
    "df=pd.DataFrame(vectorizer.fit_transform(corpus).toarray(),columns=coln)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Separates the words, ignores stop word \"the\" and \"is\",it also reads the document one time separating each of the words,\n",
    "then a second time separating in 2 words due to the n-gram_range(1,2)''' \n",
    "\n",
    "#instacia um objeto com uma função que lida com o pré-processamento e tokenização\n",
    "bi_analyze = bigram_vectorizer.build_analyzer()\n",
    "\n",
    "#pré-processa e tokeniza a string dada de acordo com os parâmetros definidos anteriormente (bi-gram)\n",
    "bi_analyze(\"This is a text document to analyze.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creates another sparce matrix using the bigram_vectorizer method, this one is bigger than the first method because the additional\n",
    "2-gram sparsing, it searches the document in 1-grams first then the bigrams \"\"\"\n",
    "\n",
    "#instacia um objeto com uma matriz com informação acerca da frequencia das palavras em cada documento de corpus\n",
    "tf_bi = bigram_vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "#mostra os tokens correspondente a cada coluna da matriz\n",
    "print(bigram_vectorizer.get_feature_names())\n",
    "\n",
    "print()\n",
    "\n",
    "#matriz das frequências de palavras por documento\n",
    "#cada linha é respeitante a um documento\n",
    "#cada coluna é respeitante a um token (palavra no caso uni-gram)\n",
    "print(tf_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostra informação acerca da frequência do token dado no corpus\n",
    "bigram_vectorizer.vocabulary_.get('document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF and the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termCollFreq = np.sum(tf_uni != 0, axis = 0) #frequencia de cada palavra no conjunto dos documentos\n",
    "docLen = np.sum(tf_uni, axis = 1) #numero total de palavras no conjunto dos documentos\n",
    "\n",
    "idf = np.log(np.size(corpus)/termCollFreq) #indice de raridade de cada palavra\n",
    "idf_rows = np.dot(np.ones((np.size(corpus),1)), idf.reshape(1,np.size(idf)))\n",
    "tfidf = tf_uni*idf_rows  #peso final de cada palavra em cada documento\n",
    "\n",
    "docNorms = np.sqrt(np.sum(np.power(tfidf,2), axis = 1)) #norma de cada documento\n",
    "        \n",
    "print(\"\\ntf:\\n\", tf_uni)\n",
    "print(\"\\nidf:\\n\", idf)\n",
    "print(\"\\ntfidf:\\n\", tfidf)\n",
    "print(\"\\ndocnorms:\\n\", docNorms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'document'\n",
    "#checks each column of the features and only keeps the ones that are equal to the query\n",
    "query_vector = vectorizer.transform([query]).toarray()\n",
    "#Norm of the created vector\n",
    "queryNorm = np.sqrt(np.sum(np.power(query_vector, 2), axis = 1))\n",
    "\n",
    "#Scores the query_vector for each document.\n",
    "#The second document has the same frequencie of the word document as the first and forth, but due to a bigger docNorm because,\n",
    "#this document has more words and the score is lower.\n",
    "doc_scores = np.dot(query_vector, tfidf.T)/(docNorms*queryNorm)\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "q_df=pd.DataFrame(vectorizer.transform([query]).toarray(),columns=coln)\n",
    "print(q_df[q_df!=0].dropna(axis=1).columns)\n",
    "#range(1:(np.sum(q_df.values)))\n",
    "#np.sum(q_df,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index\n",
    "The matricial implementation is not scalable because it computes the similarity for all documents in the collection. However, one should only compute the similarity for the documents containing the query words. This is where the inverted index comes to our rescue.\n",
    "\n",
    "Read the inverted index implementation presented next. Describe in your own words how the cosine similarity should be implemented with the inverted index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "#Creates a dictionary whit the posting lists and the feature names\n",
    "i = 0\n",
    "inverted_index = dict()\n",
    "for token in features:\n",
    "    print(\"==== Creating the posting list for token \\\"\", token, \"\\\"\")\n",
    "    docs_with_token = np.where(tf_uni[:,i] != 0)\n",
    "    len = np.size(docs_with_token,1)\n",
    "    \n",
    "    postings_matrix = np.concatenate([tf_uni[docs_with_token,i], docs_with_token])\n",
    "    postings_list = list(map(tuple, postings_matrix.T))\n",
    "    inverted_index[token] = postings_list\n",
    "    # each line shows the frequencie of the word and the the correspondent document where the word was found\n",
    "    # this is used to map the information on the database.\n",
    "    print(postings_list)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the Vector Space Model, run the experiments of section 4.\n",
    "\n",
    "We advice you to use an external Python IDE for editing more complex implementations. **The Notebook should be used as a notebook, not as an IDE**. Your implementations should be organized on external classes as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RetrievalModelsMatrix as b\n",
    "\n",
    "aa = b.RetrievalModelsMatrix(tf_uni, vectorizer)\n",
    "#unfinished in retrieval methods \n",
    "#aa.score_lmd(\"document\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeanAveragePrecision as m\n",
    "bb=m.MeanAveragePrecision(tf_uni,vectorizer)\n",
    "\n",
    "print(bb.cumulative_pscore('second'))  #Will be used to determine the precision recall curve\n",
    "bb.recall('second')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.pr_curve('document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval Models\n",
    "\n",
    "In this section you will implement three of the most popular retrieval model. After finishing each retrieval model implementation, run the experiments of section 4 with the new model.\n",
    "\n",
    "### Language Model with Jelineck-Mercer Smoothing (20%)\n",
    "The family of Language Models for retrieval build on the density distribution of the terms over each document and the density distribution of terms over the collection of documents.\n",
    "\n",
    "There several ways of avoiding the zero probabilities problem with term smoothing.  The Jelineck-Mercer smoothing model uses a mixture of probabilities between the document model $M_d$ and the corpus model $M_c$:\n",
    "\n",
    "$$p(q|d,C)= \\lambda \\cdot p(q|M_d) + (1-\\lambda)\\cdot p(q|M_c)$$\n",
    "\n",
    "Implement the LMJM retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p(q|Md) = probabilidade do termo da query aparecer no documento d =\n",
    "#         = nr vezes termo t no doc / nr total de termos do doc\n",
    "\n",
    "# p(q|Mc) = probabilidade do termo da query no corpus =\n",
    "#         = nr vezes termo t no corpus / nr total de termos do corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam: 0.5\n",
      "\n",
      "corpus: ['Jackson one most talented entertainers all time', 'Michael Jackson anointed himself King Pop']\n",
      "\n",
      "tf:\n",
      "[[1 0 1 0 1 0 0 1 1 0 1 1]\n",
      " [0 1 0 1 1 1 1 0 0 1 0 0]]\n",
      "\n",
      "query_vector: [[0 0 0 0 1 0 1 0 0 0 0 0]]\n",
      "\n",
      "total_tokens_corpus: 13\n",
      "\n",
      "Mc: [0.07692308 0.07692308 0.07692308 0.07692308 0.15384615 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308]\n",
      "\n",
      "tokens_per_doc: [7 6]\n",
      "\n",
      "Pd: [[0.14285714 0.         0.14285714 0.         0.14285714 0.\n",
      "  0.         0.14285714 0.14285714 0.         0.14285714 0.14285714]\n",
      " [0.         0.16666667 0.         0.16666667 0.16666667 0.16666667\n",
      "  0.16666667 0.         0.         0.16666667 0.         0.        ]]\n",
      "\n",
      "Pc: [0.07692308 0.07692308 0.07692308 0.07692308 0.15384615 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308]\n",
      "\n",
      "Ed: [[1.         1.         1.         1.         0.14285714 1.\n",
      "  0.         1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         0.16666667 1.\n",
      "  0.16666667 1.         1.         1.         1.         1.        ]]\n",
      "\n",
      "Ec: [[1.         1.         1.         1.         0.15384615 1.\n",
      "  0.07692308 1.         1.         1.         1.         1.        ]]\n",
      "\n",
      "scores: [0.00570583 0.01951841]\n",
      "\n",
      "query: Michael Jackson\n",
      "corpus: ['Jackson one most talented entertainers all time', 'Michael Jackson anointed himself King Pop']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "lam = 0.5; print(\"lam:\",lam) #escolher o lambda ---> lambda\n",
    "\n",
    "corpus = ['Jackson one most talented entertainers all time',\n",
    "          'Michael Jackson anointed himself King Pop']\n",
    "print(\"\\ncorpus:\",corpus)\n",
    "\n",
    "tf = vectorizer.fit_transform(corpus).toarray(); #numero de vezes que cada token aparece em cada documento ---> f_td\n",
    "print(\"\\ntf:\"); print(tf)\n",
    "\n",
    "query = \"Michael Jackson\"; query_vector = vectorizer.transform([query]).toarray();\n",
    "print(\"\\nquery_vector:\",query_vector)\n",
    "\n",
    "\n",
    "#numero de tokens no corpus (soma da soma colunas da matriz tf)\n",
    "total_tokens_corpus = sum(np.sum(tf,axis=0)); print(\"\\ntotal_tokens_corpus:\", total_tokens_corpus)\n",
    "\n",
    "#frequencia de cada token no corpus (soma de cada coluna da tf a dividir pelo numero total de tokens do corpus) ---> Mc(t)\n",
    "Mc = np.sum(tf,axis=0) / total_tokens_corpus ; print(\"\\nMc:\",Mc)\n",
    "\n",
    "#numero de tokens em cada documento (soma de cada linha da matriz tf)  ---> |d|\n",
    "tokens_per_doc  = np.sum(tf,axis=1); print(\"\\ntokens_per_doc:\",tokens_per_doc)\n",
    "\n",
    "\n",
    "#Calculo dos scores\n",
    "\n",
    "#probabilidades\n",
    "Pd = tf / tokens_per_doc[:,None]; print(\"\\nPd:\", Pd)\n",
    "Pc = Mc; print(\"\\nPc:\", Pc)\n",
    "\n",
    "#elevar ao vetor da query (query_vector) ---> P(t|Md,Mc) ^ q(t)\n",
    "Ed = np.power(Pd, query_vector); print(\"\\nEd:\", Ed)\n",
    "Ec = np.power(Pc, query_vector); print(\"\\nEc:\", Ec)\n",
    "\n",
    "#produto das probabilidades ---> produtorio( P(t|Md,Mc)^ q(t) )\n",
    "scores = np.prod(lam*Ed + (1-lam)*Ec, axis=1)\n",
    "print(\"\\nscores:\",scores)\n",
    "\n",
    "\n",
    "#compara os resultados com os documentos do corpus para ver se fazem sentido\n",
    "print(\"\\nquery:\", query)\n",
    "print(\"corpus:\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00570579 0.01951802]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import RetrievalModelsMatrix as b\n",
    "\n",
    "corpus = ['Jackson one most talented entertainers all time',\n",
    "          'Michael Jackson anointed himself King Pop']\n",
    "\n",
    "query = \"Michael Jackson\"\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tf = vectorizer.fit_transform(corpus).toarray()\n",
    "query_vector = vectorizer.transform([query]).toarray()\n",
    "\n",
    "aa = b.RetrievalModelsMatrix(tf, vectorizer)\n",
    "\n",
    "doc_scores=aa.score_lmjm(query,0.5)\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the LMJM retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMJM model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model with Dirichlet Smoothing (20%)\n",
    "Another way of avoiding the zero probabilities problem is with the Dirichlet smoothing model that uses a mixture of frequencies between the term document frequencies $f_{t,c}$ and the term corpus frequency $\\mu \\cdot M_c(t)$:\n",
    "\n",
    "$$p(t|M_d, M_c)= \\frac{f_{t,d}+\\mu \\cdot M_c(t)}{|d| + \\mu}$$\n",
    "\n",
    "Implement the LMD retrieval model using the matricial definitions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miu: 100\n",
      "\n",
      "corpus: ['Jackson one most talented entertainers all time', 'Michael Jackson anointed himself King Pop']\n",
      "\n",
      "tf:\n",
      "[[1 0 1 0 1 0 0 1 1 0 1 1]\n",
      " [0 1 0 1 1 1 1 0 0 1 0 0]]\n",
      "\n",
      "query_vector: [[0 0 0 0 1 0 1 0 0 0 0 0]]\n",
      "\n",
      "total_tokens_corpus: 13\n",
      "\n",
      "Mc: [0.07692308 0.07692308 0.07692308 0.07692308 0.15384615 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308]\n",
      "\n",
      "tokens_per_doc: [7 6]\n",
      "\n",
      "p: [[0.08123652 0.07189073 0.08123652 0.07189073 0.15312725 0.07189073\n",
      "  0.07189073 0.08123652 0.08123652 0.07189073 0.08123652 0.08123652]\n",
      " [0.07256894 0.0820029  0.07256894 0.0820029  0.15457184 0.0820029\n",
      "  0.0820029  0.07256894 0.07256894 0.0820029  0.07256894 0.07256894]]\n",
      "\n",
      "e: [[1.         1.         1.         1.         0.15312725 1.\n",
      "  0.07189073 1.         1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.         0.15457184 1.\n",
      "  0.0820029  1.         1.         1.         1.         1.        ]]\n",
      "\n",
      "scores: [0.01100843 0.01267534]\n",
      "\n",
      "query: Michael Jackson\n",
      "corpus: ['Jackson one most talented entertainers all time', 'Michael Jackson anointed himself King Pop']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "miu = 100; print(\"miu:\",miu) #escolher o miu ---> miu\n",
    "\n",
    "corpus = ['Jackson one most talented entertainers all time',\n",
    "          'Michael Jackson anointed himself King Pop']\n",
    "print(\"\\ncorpus:\",corpus)\n",
    "\n",
    "tf = vectorizer.fit_transform(corpus).toarray(); #numero de vezes que cada token aparece em cada documento ---> f_td\n",
    "print(\"\\ntf:\"); print(tf)\n",
    "\n",
    "query = \"Michael Jackson\"; query_vector = vectorizer.transform([query]).toarray();\n",
    "print(\"\\nquery_vector:\",query_vector)\n",
    "\n",
    "\n",
    "#numero de tokens no corpus (soma da soma colunas da matriz tf)\n",
    "total_tokens_corpus = sum(np.sum(tf,axis=0)); print(\"\\ntotal_tokens_corpus:\", total_tokens_corpus)\n",
    "\n",
    "#frequencia de cada token no corpus (soma de cada coluna da tf a dividir pelo numero total de tokens do corpus) ---> Mc(t)\n",
    "Mc = np.sum(tf,axis=0) / total_tokens_corpus ; print(\"\\nMc:\",Mc)\n",
    "\n",
    "#numero de tokens em cada documento (soma de cada linha da matriz tf)  ---> |d|\n",
    "tokens_per_doc  = np.sum(tf,axis=1); print(\"\\ntokens_per_doc:\",tokens_per_doc)\n",
    "\n",
    "\n",
    "#Calculo dos scores\n",
    "\n",
    "#probabilidades ---> P(t|Md,Mc)\n",
    "p = (tf + miu*Mc)/(tokens_per_doc[:,None] + miu); print(\"\\np:\",p)\n",
    "\n",
    "#elevar ao vetor da query (query_vector) ---> P(t|Md,Mc) ^ q(t)\n",
    "e = np.power(p, query_vector); print(\"\\ne:\",e)\n",
    "\n",
    "#produto das probabilidades ---> produtorio( P(t|Md,Mc)^ q(t) )\n",
    "scores = np.prod(e, axis=1); print(\"\\nscores:\",scores)\n",
    "\n",
    "\n",
    "#compara os resultados com os documentos do corpus para ver se fazem sentido\n",
    "print(\"\\nquery:\", query)\n",
    "print(\"corpus:\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01100843 0.01267534]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import RetrievalModelsMatrix as b\n",
    "\n",
    "corpus = ['Jackson one most talented entertainers all time',\n",
    "          'Michael Jackson anointed himself King Pop']\n",
    "\n",
    "query = \"Michael Jackson\"\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tf = vectorizer.fit_transform(corpus).toarray()\n",
    "query_vector = vectorizer.transform([query]).toarray()\n",
    "\n",
    "aa = b.RetrievalModelsMatrix(tf, vectorizer)\n",
    "\n",
    "doc_scores = aa.score_lmd(query, 100)\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the LMD retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMD model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM 25 (20%)\n",
    "\n",
    "The BM25 is model is an evolution of the tf-idf weighting based on a two Poisson distribution per term. It is obviously impossible to estimate each term distribution -- the approximation to the two Poisson distribution is given by the expression:\n",
    "\n",
    "$$RSV = \\sum q_t \\cdot \\frac{f_{t,d}(k_1 + 1)}{k_1 ((1-b) + b(\\frac{l_d}{l_avg})) + f_{t,d} }\\cdot IDF_t$$\n",
    "\n",
    "Implement the BM5 retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: BM25 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the BM25 retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: BM25 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the implemented Retrieval Models, run the experiments of section 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pseudo-Relevance Feedback (RM3) (20%)\n",
    "\n",
    "Using the RM3 Model, run the experiments of section 4.\n",
    "\n",
    "Implement the RM3 retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "corpus: ['Jackson one most talented entertainers all time', 'Michael Jackson anointed himself King Pop']\n",
      "\n",
      "tf:\n",
      "[[1 0 1 0 1 0 0 1 1 0 1 1]\n",
      " [0 1 0 1 1 1 1 0 0 1 0 0]]\n",
      "\n",
      "query_vector: [[0 0 0 0 1 0 1 0 0 0 0 0]]\n",
      "\n",
      "tokens_per_doc: [7 6]\n",
      "\n",
      "alfa: 0.5\n",
      "\n",
      "top_docs: 1\n",
      "\n",
      "initial_scores: [0.00570579 0.01951802]\n",
      "\n",
      "sorted_scores: [0.00570579 0.01951802]\n",
      "\n",
      "threshold: 0.01951801721205193\n",
      "\n",
      "best_scores: [0.         0.01951802]\n",
      "\n",
      "Pd: [[0.14285714 0.         0.14285714 0.         0.14285714 0.\n",
      "  0.         0.14285714 0.14285714 0.         0.14285714 0.14285714]\n",
      " [0.         0.16666667 0.         0.16666667 0.16666667 0.16666667\n",
      "  0.16666667 0.         0.         0.16666667 0.         0.        ]]\n",
      "\n",
      "P_RM1: [0.       0.003253 0.       0.003253 0.003253 0.003253 0.003253 0.\n",
      " 0.       0.003253 0.       0.      ]\n",
      "\n",
      "new_query: [[0.        0.0016265 0.        0.0016265 0.5016265 0.0016265 0.5016265\n",
      "  0.        0.        0.0016265 0.        0.       ]]\n",
      "\n",
      "scores: [0.00325868 0.13440704]\n",
      "\n",
      "query: Michael Jackson\n",
      "corpus: ['Jackson one most talented entertainers all time', 'Michael Jackson anointed himself King Pop']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import RetrievalModelsMatrix as b\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = ['Jackson one most talented entertainers all time',\n",
    "          'Michael Jackson anointed himself King Pop']\n",
    "print(\"\\ncorpus:\",corpus)\n",
    "\n",
    "tf = vectorizer.fit_transform(corpus).toarray(); #numero de vezes que cada token aparece em cada documento ---> f_td\n",
    "print(\"\\ntf:\"); print(tf)\n",
    "\n",
    "query = \"Michael Jackson\"; query_vector = vectorizer.transform([query]).toarray();\n",
    "print(\"\\nquery_vector:\",query_vector)\n",
    "\n",
    "#numero de tokens em cada documento (soma de cada linha da matriz tf)  ---> |d|\n",
    "tokens_per_doc  = np.sum(tf,axis=1); print(\"\\ntokens_per_doc:\",tokens_per_doc)\n",
    "\n",
    "\n",
    "aa = b.RetrievalModelsMatrix(tf, vectorizer)\n",
    "\n",
    "\n",
    "alfa = 0.5; print(\"\\nalfa:\",alfa) #escolher o alfa ---> alfa\n",
    "\n",
    "top_docs = 1; print(\"\\ntop_docs:\", top_docs) #escolher o nr de documentos a considerar ---> top_docs\n",
    "\n",
    "#doc_scores\n",
    "initial_scores = aa.score_lmjm(query, 0.5); print(\"\\ninitial_scores:\", initial_scores)\n",
    "        \n",
    "#ordena os doc_scores do maior para o menor\n",
    "sorted_scores = np.sort(initial_scores); print(\"\\nsorted_scores:\", sorted_scores)\n",
    "        \n",
    "#minimo das probabilidades dos documentos relevante\n",
    "threshold = sorted_scores[-1*top_docs]; print(\"\\nthreshold:\", threshold)\n",
    "        \n",
    "#documentos mais relevantes\n",
    "best_scores = initial_scores * (initial_scores >= threshold); print(\"\\nbest_scores:\", best_scores)\n",
    "        \n",
    "Pd = tf / tokens_per_doc[:,None]; print(\"\\nPd:\", Pd)\n",
    "        \n",
    "P_RM1 = np.sum(Pd * best_scores[:,None], axis=0); print(\"\\nP_RM1:\", P_RM1)\n",
    "\n",
    "new_query = (1-alfa)*query_vector + alfa*P_RM1; print(\"\\nnew_query:\", new_query)\n",
    "\n",
    "scores = aa.score_lmjm(new_query, 0.5, query_to_vector=False); print(\"\\nscores:\",scores)\n",
    "\n",
    "\n",
    "#compara os resultados com os documentos do corpus para ver se fazem sentido\n",
    "print(\"\\nquery:\", query)\n",
    "print(\"corpus:\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00325868 0.13440708]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import RetrievalModelsMatrix as b\n",
    "\n",
    "corpus = ['Jackson one most talented entertainers all time',\n",
    "          'Michael Jackson anointed himself King Pop']\n",
    "\n",
    "query = \"Michael Jackson\"\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tf = vectorizer.fit_transform(corpus).toarray()\n",
    "query_vector = vectorizer.transform([query]).toarray()\n",
    "\n",
    "aa = b.RetrievalModelsMatrix(tf, vectorizer)\n",
    "\n",
    "doc_scores = aa.score_rm3(query, 0.5, 1, aa.score_lmjm, 0.5, True)\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the RM3 retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: RM3 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the implemented RM3 model, run the experiments of section 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiments and Results (20%)\n",
    "The goal of this section is to compare experimentally the different retrieval models. In this section you must:\n",
    "- Load the Cranfield documents.\n",
    "- Run the implemented retrieval models\n",
    "- Plot the precision-recall curves.\n",
    "- Compute MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  1400\n",
      "Number of queries:  225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MPM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MPM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import simpleparser as parser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import collectionloaders\n",
    "import RetrievalModelsMatrix as model\n",
    "\n",
    "verbose = False\n",
    "bigrams = True\n",
    "\n",
    "### 1. Load the corpus\n",
    "cranfield = collectionloaders.CranfieldTestBed()\n",
    "\n",
    "### 2. Parse the corpus\n",
    "# Tokenize, stem and remove stop words\n",
    "def vsm_test(bigrams):\n",
    "    \n",
    "    \n",
    "    if not bigrams:\n",
    "        vectorizer = CountVectorizer()\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', \n",
    "                                        min_df=1, stop_words = {'the', 'is'})\n",
    "    \n",
    "    corpus = parser.stemCorpus(cranfield.corpus_cranfield['abstract'])\n",
    "    \n",
    "    ### 3. Create the model\n",
    "    # Compute the term frequencies matrix and the model statistics\n",
    "    tf_cranfield = vectorizer.fit_transform(corpus).toarray()\n",
    "    models = model.RetrievalModelsMatrix(tf_cranfield, vectorizer)\n",
    "    \n",
    "    ### 4. Run the queries over the corpus\n",
    "    i = 1\n",
    "    map_vsm = 0\n",
    "    precision_vsm = []\n",
    "\n",
    "    for query in cranfield.queries:\n",
    "        # Parse the query and compute the document scores\n",
    "        scores = models.score_vsm(parser.stemSentence(query))\n",
    "    \n",
    "        # Do the evaluation\n",
    "        [average_precision, precision, recall, thresholds] = cranfield.eval(scores, i)\n",
    "        map_vsm = map_vsm + average_precision\n",
    "        precision_vsm.append(precision)\n",
    "        \n",
    "        # Some messages...\n",
    "        if verbose:\n",
    "            plt.plot(recall, precision, color='silver', alpha=0.1)\n",
    "            print('qid =',i, 'VSM     AP=',average_precision)\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "    del models #deletes class instance\n",
    "    map_vsm = map_vsm/cranfield.num_queries\n",
    "    return map_vsm,recall,precision_vsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests the vsm retrieval model \n",
    "    \n",
    "First test without bigrams and second with bigrams\n",
    "\n",
    "Stores the values of the tests in a 3 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapl=[]\n",
    "recl=[]\n",
    "precl=[]\n",
    "for b in [False,True]:\n",
    "    new_map,new_recall,new_precision=vsm_test(b)\n",
    "    mapl.append(new_map)\n",
    "    recl.append(new_recall)\n",
    "    precl.append(new_precision)\n",
    "    \n",
    "ind=np.argmax(mapl)  #finds the index of the biggest map value\n",
    "map_vsm=mapl[ind]\n",
    "recall=recl[ind]\n",
    "precision_vsm=precl[ind]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compares the Precision-Recall curves of the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recl[0], np.mean(precl[0],axis=0), color='b', alpha=1,label=' normal ngrams')\n",
    "plt.plot(recl[1], np.mean(precl[1],axis=0), color='r', alpha=1,label=\" bigrams\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP= 0.2939123097084909\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Show results\n",
    "print('MAP=',map_vsm)\n",
    "\n",
    "plt.plot(recall, np.mean(precision_vsm,axis=0), color='b', alpha=1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.fill_between(recall, \n",
    "                 np.mean(precision_vsm,axis=0)-np.std(precision_vsm,axis=0), \n",
    "                 np.mean(precision_vsm,axis=0)+np.std(precision_vsm,axis=0), facecolor='b', alpha=0.1)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall (MAP={0:0.2f})'.format(map_vsm))\n",
    "plt.savefig('results/prec-recall.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = parser.stemCorpus(cranfield.corpus_cranfield['abstract'])\n",
    "    \n",
    "    ### 3. Create the model\n",
    "    # Compute the term frequencies matrix and the model statistics\n",
    "tf_cranfield = vectorizer.fit_transform(corpus).toarray()\n",
    "models = model.RetrievalModelsMatrix(tf_cranfield, vectorizer)\n",
    "\n",
    "def test_model(rm,par):\n",
    "    #rm=models.score_lmjm or models.score_ldm\n",
    "    ### 4. Run the queries over the corpus\n",
    "    i = 1\n",
    "    map_vsm = 0\n",
    "    precision_vsm = []\n",
    "\n",
    "    for query in cranfield.queries:\n",
    "        # Parse the query and compute the document scores\n",
    "        scores = np.nan_to_num(rm(parser.stemSentence(query),par))\n",
    "        \n",
    "        # Do the evaluation\n",
    "        [average_precision, precision, recall, thresholds] = cranfield.eval(scores, i)\n",
    "        map_vsm = map_vsm + average_precision\n",
    "        precision_vsm.append(precision)\n",
    "        \n",
    "        # Some messages...\n",
    "        if verbose:\n",
    "            plt.plot(recall, precision, color='silver', alpha=0.1)\n",
    "            print('qid =',i, 'VSM     AP=',average_precision)\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "    \n",
    "    map_vsm = map_vsm/cranfield.num_queries\n",
    "    return map_vsm,recall,precision_vsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_tests(p_start,p_end,n,model):\n",
    "    mapl=[]\n",
    "    recl=[]\n",
    "    precl=[]\n",
    "\n",
    "    pv=np.linspace(p_start,p_end,n)\n",
    "    for p in range(0,n):\n",
    "        new_map,new_recall,new_precision=test_model(model,pv[p])\n",
    "        mapl.append(new_map)\n",
    "        recl.append(new_recall)\n",
    "        precl.append(new_precision)\n",
    "    \n",
    "    ind=np.argmax(mapl)  #finds the index of the biggest map value\n",
    "    map_vsm=mapl[ind]\n",
    "    recall=recl[ind]\n",
    "    precision_vsm=precl[ind]\n",
    "    best_p=pv[ind]\n",
    "    return best_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tests(0.1,1,5,models.score_lmjm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and discussion\n",
    "\n",
    "\n",
    "The following table summarizes the MAP and P10 results:\n",
    "\n",
    "| Retrieval Model | P10 | MAP   |\n",
    "|-----------------|-----|-------|\n",
    "| VSM             | ?   | {{map_vsm}} |\n",
    "| LMD             | ?   | ? |\n",
    "| LMJM             | ?   | ? |\n",
    "| BM25             | ?   | ? |\n",
    "\n",
    "![](results/prec-recall.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
